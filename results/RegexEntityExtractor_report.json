{
  "last_name": {
    "precision": 0.4,
    "recall": 0.8571428571428571,
    "f1-score": 0.5454545454545455,
    "support": 7,
    "confused_with": {}
  },
  "element": {
    "precision": 1.0,
    "recall": 0.55,
    "f1-score": 0.7096774193548387,
    "support": 20,
    "confused_with": {}
  },
  "first_name": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4,
    "confused_with": {
      "last_name": 1
    }
  },
  "semester": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 12,
    "confused_with": {}
  },
  "module": {
    "precision": 1.0,
    "recall": 0.1111111111111111,
    "f1-score": 0.19999999999999998,
    "support": 36,
    "confused_with": {}
  },
  "sector": {
    "precision": 1.0,
    "recall": 0.95,
    "f1-score": 0.9743589743589743,
    "support": 60,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.8666666666666667,
    "recall": 0.5611510791366906,
    "f1-score": 0.6812227074235807,
    "support": 139
  },
  "macro avg": {
    "precision": 0.5666666666666667,
    "recall": 0.4113756613756614,
    "f1-score": 0.40491515652805976,
    "support": 139
  },
  "weighted avg": {
    "precision": 0.8546762589928057,
    "recall": 0.5611510791366906,
    "f1-score": 0.6019659616317774,
    "support": 139
  },
  "accuracy": 0.9153936545240893
}